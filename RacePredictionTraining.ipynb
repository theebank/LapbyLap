{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T18:35:20.263212Z",
     "start_time": "2024-08-20T18:35:20.220311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "import math\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from io import BytesIO\n",
    "from datetime import datetime, timedelta"
   ],
   "id": "7bb126af1af47b09",
   "outputs": [],
   "execution_count": 457
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preparation\n",
    "\n",
    "Create a CSV file of information for one race, each row contains info for each lap\n",
    "- 0th lap will be the driver's best qualifying lap"
   ],
   "id": "a3cea317ff31da4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:56:47.622939Z",
     "start_time": "2024-08-20T15:56:47.111222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = urlopen('https://api.openf1.org/v1/sessions?csv=true')\n",
    "data = pd.read_csv(BytesIO(res.read()))\n",
    "data.to_csv(\"LapData/Sessions.csv\", index=False)"
   ],
   "id": "2050be3fd5c5ac3b",
   "outputs": [],
   "execution_count": 426
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:56:58.874835Z",
     "start_time": "2024-08-20T15:56:58.850849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Sessions = pd.read_csv(\"Sessions.csv\")\n",
    "races = Sessions.query(\"session_type == 'Race' and session_name != 'Sprint'\")\n",
    "qualis = Sessions.query(\"session_type == 'Qualifying' and session_name == 'Qualifying'\")\n"
   ],
   "id": "e77d1469a0cbbf49",
   "outputs": [],
   "execution_count": 427
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "For each Track:\n",
    "- Need to find all data for qualifying and race (Every lap they put in)\n",
    "- Create a dataframe of every driver and all the laps they did including whether they pit, retired, etc\n",
    "- Each row needs to have Lap time"
   ],
   "id": "58357fcca1a65d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:52:14.558006Z",
     "start_time": "2024-08-20T15:52:14.548794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "QualiAndRaceSessions= Sessions[Sessions['session_name'].isin(['Qualifying', 'Race'])]\n",
    "print(QualiAndRaceSessions)    "
   ],
   "id": "549b45901ef837f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     circuit_key circuit_short_name country_code  country_key   country_name  \\\n",
      "6             63             Sakhir          BRN           36        Bahrain   \n",
      "7             63             Sakhir          BRN           36        Bahrain   \n",
      "11           149             Jeddah          KSA          153   Saudi Arabia   \n",
      "12           149             Jeddah          KSA          153   Saudi Arabia   \n",
      "16            10          Melbourne          AUS            5      Australia   \n",
      "..           ...                ...          ...          ...            ...   \n",
      "171            2        Silverstone          GBR            2  Great Britain   \n",
      "175            4        Hungaroring          HUN           14        Hungary   \n",
      "176            4        Hungaroring          HUN           14        Hungary   \n",
      "180            7  Spa-Francorchamps          BEL           16        Belgium   \n",
      "181            7  Spa-Francorchamps          BEL           16        Belgium   \n",
      "\n",
      "                      date_end                 date_start gmt_offset  \\\n",
      "6    2023-03-04 16:00:00+00:00  2023-03-04 15:00:00+00:00   03:00:00   \n",
      "7    2023-03-05 17:00:00+00:00  2023-03-05 15:00:00+00:00   03:00:00   \n",
      "11   2023-03-18 18:00:00+00:00  2023-03-18 17:00:00+00:00   03:00:00   \n",
      "12   2023-03-19 19:00:00+00:00  2023-03-19 17:00:00+00:00   03:00:00   \n",
      "16   2023-04-01 06:00:00+00:00  2023-04-01 05:00:00+00:00   11:00:00   \n",
      "..                         ...                        ...        ...   \n",
      "171  2024-07-07 16:00:00+00:00  2024-07-07 14:00:00+00:00   01:00:00   \n",
      "175  2024-07-20 15:00:00+00:00  2024-07-20 14:00:00+00:00   02:00:00   \n",
      "176  2024-07-21 15:00:00+00:00  2024-07-21 13:00:00+00:00   02:00:00   \n",
      "180  2024-07-27 15:00:00+00:00  2024-07-27 14:00:00+00:00   02:00:00   \n",
      "181  2024-07-28 15:00:00+00:00  2024-07-28 13:00:00+00:00   02:00:00   \n",
      "\n",
      "              location  meeting_key  session_key session_name session_type  \\\n",
      "6               Sakhir         1141         7768   Qualifying   Qualifying   \n",
      "7               Sakhir         1141         7953         Race         Race   \n",
      "11              Jeddah         1142         7775   Qualifying   Qualifying   \n",
      "12              Jeddah         1142         7779         Race         Race   \n",
      "16           Melbourne         1143         7783   Qualifying   Qualifying   \n",
      "..                 ...          ...          ...          ...          ...   \n",
      "171        Silverstone         1240         9558         Race         Race   \n",
      "175           Budapest         1241         9562   Qualifying   Qualifying   \n",
      "176           Budapest         1241         9566         Race         Race   \n",
      "180  Spa-Francorchamps         1242         9570   Qualifying   Qualifying   \n",
      "181  Spa-Francorchamps         1242         9574         Race         Race   \n",
      "\n",
      "     year  \n",
      "6    2023  \n",
      "7    2023  \n",
      "11   2023  \n",
      "12   2023  \n",
      "16   2023  \n",
      "..    ...  \n",
      "171  2024  \n",
      "175  2024  \n",
      "176  2024  \n",
      "180  2024  \n",
      "181  2024  \n",
      "\n",
      "[72 rows x 14 columns]\n"
     ]
    }
   ],
   "execution_count": 420
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T15:52:18.296983Z",
     "start_time": "2024-08-20T15:52:18.285317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def addRow(circuitkey, driver_ids, currentposition, pits, laps,status):\n",
    "    row = {}\n",
    "    row['CircuitID'] = circuitkey\n",
    "    for j in range(len(driver_ids)):\n",
    "        row[f'driver_ID_{j+1}'] = driver_ids[j]\n",
    "        row[f'position{j+1}'] = currentposition[j]\n",
    "        row[f'inPit{j+1}'] = pits[j]\n",
    "        row[f'status{j+1}'] = status[j]\n",
    "        row[f'laptime{j+1}'] = laps[j]\n",
    "\n",
    "    return row"
   ],
   "id": "70cf1820ab55327b",
   "outputs": [],
   "execution_count": 421
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T17:11:15.600695Z",
     "start_time": "2024-08-20T17:07:32.049344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loop over each track per year\n",
    "for i in tqdm(range(0,len(QualiAndRaceSessions),2)):\n",
    "    location = QualiAndRaceSessions.iloc[i]['location']\n",
    "    year = QualiAndRaceSessions.iloc[i]['year']\n",
    "    circuitkey = QualiAndRaceSessions.iloc[i]['circuit_key']\n",
    "    QualifyingKey = QualiAndRaceSessions.iloc[i]['session_key']\n",
    "    RaceKey = QualiAndRaceSessions.iloc[i+1]['session_key']\n",
    "    \n",
    "    print(location,year, QualifyingKey, RaceKey)\n",
    "    # Gather all data pertaining to qualifying from session_key for each driver\n",
    "    res = urlopen(\"https://api.openf1.org/v1/laps?csv=true&session_key=\" + str(QualifyingKey))\n",
    "    QualiLaps = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/pit?csv=true&session_key=\"+str(QualifyingKey))\n",
    "    QualiPits = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/race_control?csv=true&session_key=\"+str(QualifyingKey))\n",
    "    QualiRaceControl = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/stints?csv=true&session_key=\"+str(QualifyingKey))\n",
    "    QualiStints = pd.read_csv(BytesIO(res.read()))\n",
    "    # Create a DataFrame with each row having for each driver: Driver_ID, position, inpit, status, laptime\n",
    "    # Each Row needs to have Driver_ID, Driver Name, Position(Maybe?), whether they pitted that lap, status, laptime, tire age, compound, If there was a flag,\n",
    "        \n",
    "    # Gather all data pertaining to race from session_key for each driver\n",
    "    res = urlopen(\"https://api.openf1.org/v1/position?csv=true&session_key=\" + str(RaceKey))\n",
    "    RacePositions = pd.read_csv(BytesIO(res.read()))\n",
    "    RaceStartPos = RacePositions[:20].sort_values(by='position', ascending=True)\n",
    "    \n",
    "    res = urlopen(\"https://api.openf1.org/v1/laps?csv=true&session_key=\" + str(RaceKey))\n",
    "    RaceLaps = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/pit?csv=true&session_key=\"+str(RaceKey))\n",
    "    RacePits = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/race_control?csv=true&session_key=\"+str(RaceKey))\n",
    "    RaceControl = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/stints?csv=true&session_key=\"+str(RaceKey))\n",
    "    RaceStints = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    res = urlopen(\"https://api.openf1.org/v1/sessions?csv=true&session_key=\"+str(RaceKey))\n",
    "    RaceMeeting = pd.read_csv(BytesIO(res.read()))\n",
    "\n",
    "    RaceStartTime = RaceMeeting.iloc[0]['date_start']\n",
    "    RaceStartDict = RaceStartPos.to_dict('records')\n",
    "\n",
    "    QualiLaps_sorted = QualiLaps.sort_values(by='driver_number', ascending=False)\n",
    "    R_NumLaps = RaceLaps.sort_values(by='lap_number',ascending = False).iloc[0]['lap_number']\n",
    "    \n",
    "    PositionChanges = RacePositions\n",
    "    PositionChanges['date'] = pd.to_datetime(PositionChanges['date'], format='ISO8601')\n",
    "    \n",
    "    totaltimes = {}\n",
    "    startinggrid = {}\n",
    "    crossfinishtime = []\n",
    "    currentposition = []\n",
    "    for i in RaceStartDict:\n",
    "        startinggrid[i['driver_number']]= i['position']\n",
    "        totaltimes[i['driver_number']] = 0\n",
    "        crossfinishtime.append(RaceStartTime)\n",
    "\n",
    "    driver_ids = []\n",
    "    for driver_number in RaceLaps.sort_values(by='driver_number',ascending=False)['driver_number'].unique():\n",
    "        driver_ids.append(int(driver_number))\n",
    "\n",
    "    laplist = []\n",
    "    status = [1 for _ in range(len(driver_ids))]\n",
    "    \n",
    "    laps = []\n",
    "    pits = []\n",
    "    currentposition = []\n",
    "    # 0th Lap (Qualifying Lap)\n",
    "    for driver_number in driver_ids:\n",
    "        currentposition.append(int(RaceStartPos.loc[RaceStartPos['driver_number'] == driver_number]['position'].iloc[0]))\n",
    "        q_driver_laps = QualiLaps_sorted.loc[QualiLaps_sorted['driver_number'] == driver_number]\n",
    "        if not q_driver_laps.empty:\n",
    "            fastest_lap = q_driver_laps.sort_values(by='lap_duration', ascending=True).iloc[0]['lap_duration']\n",
    "            laps.append(float(fastest_lap))\n",
    "            pits.append(False)\n",
    "        else:\n",
    "            print(\"No laps found\")\n",
    "            pits.append(True)\n",
    "            laps.append(0)\n",
    "    \n",
    "    laplist.append(addRow(circuitkey=circuitkey,\n",
    "                          driver_ids=driver_ids,\n",
    "                          currentposition=currentposition,\n",
    "                          pits=pits,\n",
    "                          laps=laps,\n",
    "                          status = status))\n",
    "    # 1st Lap (Including Formation lap and countdown)\n",
    "    SecondLapStarts = RaceLaps[RaceLaps['lap_number']==2]\n",
    "    FirstLapTimes = [-1 for _ in range(len(driver_ids))]\n",
    "    for i in range(len(driver_ids)):\n",
    "        LapStartTime = SecondLapStarts[SecondLapStarts['driver_number']==driver_ids[i]]\n",
    "        if not LapStartTime.empty:\n",
    "            LapStartTime = LapStartTime.iloc[0]['date_start']\n",
    "            crossfinishtime[i] = (datetime.fromisoformat(LapStartTime))\n",
    "            FirstLapTimes[i] = ((datetime.fromisoformat(LapStartTime)-datetime.fromisoformat(RaceStartTime)).total_seconds())\n",
    "        else:\n",
    "            status[i] = 0\n",
    "    \n",
    "    laps = []\n",
    "    pits = []\n",
    "    for driver_idx in range(len(driver_ids)):\n",
    "        pits.append(False)\n",
    "        laps.append(FirstLapTimes[driver_idx])\n",
    "    \n",
    "    laplist.append(addRow(circuitkey=circuitkey,\n",
    "                          driver_ids=driver_ids,\n",
    "                          currentposition=currentposition,\n",
    "                          pits=pits,\n",
    "                          laps=laps,\n",
    "                          status=status))\n",
    "    # Rest of race\n",
    "    lap_num = 2\n",
    "    retired = {}\n",
    "    # Current position value being used from starting grid - only needs to be updated each lap to see if anyone has made a change\n",
    "    while (lap_num < R_NumLaps+1):\n",
    "        laps = []\n",
    "        pits = []\n",
    "        for driver_idx in range(len(driver_ids)):\n",
    "            r_driver_laps =RaceLaps.loc[RaceLaps['driver_number'] == driver_ids[driver_idx]]\n",
    "            if not r_driver_laps.empty:\n",
    "                lapdata = r_driver_laps.loc[r_driver_laps['lap_number']==lap_num]\n",
    "                if not lapdata.empty:\n",
    "                    laptime = lapdata.iloc[0]['lap_duration']\n",
    "                    pitted = lapdata.iloc[0]['is_pit_out_lap']\n",
    "                    if not laptime:\n",
    "                        print(\"No laps found\")\n",
    "                    if(math.isnan(laptime)):\n",
    "                        laps.append(0)\n",
    "                        pits.append(False)\n",
    "                    else:\n",
    "                        laps.append(laptime)\n",
    "                        pits.append(pitted)\n",
    "                        totaltimes[driver_ids[driver_idx]] += laptime\n",
    "                        crossfinishtime[driver_idx] += timedelta(seconds = laptime)\n",
    "                        # Check if their position has changed\n",
    "                        filteredpositions = PositionChanges[(PositionChanges['date']<=(crossfinishtime[driver_idx]))&(PositionChanges['driver_number']==driver_ids[driver_idx])]\n",
    "                        if not filteredpositions.empty:\n",
    "                            closestrow = filteredpositions.iloc[-1]\n",
    "                            currentposition[driver_idx] = closestrow['position']\n",
    "                else:# Driver Retired\n",
    "                    laps.append(-1)\n",
    "                    pits.append(False)\n",
    "                    status[driver_idx] = 0\n",
    "    \n",
    "            else: #Driver did not start\n",
    "                laps.append(-1)\n",
    "                pits.append(False)\n",
    "                retired[driver_ids[driver_idx]] = len(retired)\n",
    "                status[driver_idx] = 0\n",
    "    \n",
    "        laplist.append(addRow(circuitkey=circuitkey,\n",
    "                              driver_ids=driver_ids,\n",
    "                              currentposition=currentposition,\n",
    "                              pits=pits,\n",
    "                              laps=laps,\n",
    "                              status=status))\n",
    "    \n",
    "        lap_num += 1\n",
    "    \n",
    "    df = pd.DataFrame(laplist)\n",
    "    df.to_csv(\"/Users/theebankumaresan/Documents/Programming/Python/f1lapbylap/f1LapbyLap/LapData/\" + f'{year}/{location}.csv',index = False)\n"
   ],
   "id": "708448e781a62d1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ce94cd65b2b4398a96a032fb7696489"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sakhir 2023 7768 7953\n",
      "Jeddah 2023 7775 7779\n",
      "Melbourne 2023 7783 7787\n",
      "Baku 2023 9064 9070\n",
      "Miami 2023 9074 9078\n",
      "Monaco 2023 9090 9094\n",
      "Barcelona 2023 9098 9102\n",
      "Montréal 2023 9106 9110\n",
      "Spielberg 2023 9112 9118\n",
      "Silverstone 2023 9122 9126\n",
      "Budapest 2023 9129 9133\n",
      "Spa-Francorchamps 2023 9135 9141\n",
      "Zandvoort 2023 9145 9149\n",
      "Monza 2023 9153 9157\n",
      "Marina Bay 2023 9161 9165\n",
      "Suzuka 2023 9169 9173\n",
      "Lusail 2023 9215 9221\n",
      "Austin 2023 9207 9213\n",
      "Mexico City 2023 9177 9181\n",
      "São Paulo 2023 9304 9205\n",
      "Las Vegas 2023 9314 9189\n",
      "Yas Island 2023 9193 9197\n",
      "Sakhir 2024 9468 9472\n",
      "Jeddah 2024 9476 9480\n",
      "Melbourne 2024 9484 9488\n",
      "Suzuka 2024 9492 9496\n",
      "Shanghai 2024 9664 9673\n",
      "Miami 2024 9498 9507\n",
      "Imola 2024 9511 9515\n",
      "Monaco 2024 9519 9523\n",
      "Montréal 2024 9527 9531\n",
      "Barcelona 2024 9535 9539\n",
      "Spielberg 2024 9541 9550\n",
      "Silverstone 2024 9554 9558\n",
      "Budapest 2024 9562 9566\n",
      "Spa-Francorchamps 2024 9570 9574\n"
     ]
    }
   ],
   "execution_count": 433
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Status - 1 is running, 0 is retired",
   "id": "40ac18db9a405d2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Make a Dataset:\n",
    "\n",
    "- Helper functions for getting information from each id"
   ],
   "id": "10051b0752667ce6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:36:10.496307Z",
     "start_time": "2024-08-20T20:36:10.324564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "drivers = pd.read_csv('Drivers.csv')\n",
    "Sessions = pd.read_csv('Sessions.csv')\n",
    "\n",
    "def driver_info(id):\n",
    "    _drivers = drivers\n",
    "    _d = _drivers.query(f'driver_number == {id}')\n",
    "    if _d.empty:\n",
    "        return None, None, None, None, None, None\n",
    "    _number = int(_d.iloc[0]['driver_number'])\n",
    "    _code = _d.iloc[0]['name_acronym']\n",
    "    _firstname = _d.iloc[0]['first_name']\n",
    "    _lastname = _d.iloc[0]['last_name']\n",
    "    _nationality = _d.iloc[0]['country_code']\n",
    "    return _number, _code, _firstname, _lastname, _nationality\n",
    "    \n",
    "def circuit_info(circuit_key):\n",
    "    _sessions = Sessions\n",
    "    _s = _sessions.query(f'circuit_key=={circuit_key}')\n",
    "    _name = _s.iloc[0]['circuit_short_name']\n",
    "    _country = _s.iloc[0]['country_name']\n",
    "    _location = _s.iloc[0]['location']\n",
    "    return _name, _country, _location"
   ],
   "id": "7a109c2cb2ee70cc",
   "outputs": [],
   "execution_count": 565
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "DataSet Class:\n",
    "\n",
    "- <strike> Initializes with a directory containing race data files organized by year </strike>\n",
    "- <strike> 3 methods for setting current year, round and next round to automatically load appropriate file </strike>\n",
    "- method for processing race data for a given index, transforming into tensors \n",
    "    - Handles NaN values by replacing them with 0 and scales features like driver IDs and lap times\n",
    "    - prepares sequences of lap times up to current lap for model input\n",
    "    - extracts and scales relevant features from dataset to create input-output pairs for model training\n",
    "- <strike> method for returning length of dataset, accounts for fact that last lap is a label </strike>\n"
   ],
   "id": "e4d350a0b0ccd7e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:33.913114Z",
     "start_time": "2024-08-20T20:51:33.866861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RaceDataSet(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dir):\n",
    "        self.year = 2023\n",
    "        self.dir = dir\n",
    "        self.currentyear = sorted(os.listdir(self.dir+f'{self.year}/'))\n",
    "        self.round = 2\n",
    "        \n",
    "        if(self.round<len(self.currentyear)):\n",
    "            self.currentrace = pd.read_csv(self.dir+f'{self.year}/{self.currentyear[self.round-1]}')\n",
    "        else:\n",
    "            self.currentrace = pd.read_csv(self.dir+f'{self.year}/{self.currentyear[-1]}')\n",
    "        \n",
    "    def set_year(self, year):\n",
    "        self.year = year\n",
    "        self.currentyear = sorted(os.listdir(self.dir+f'{self.year}/'))\n",
    "        \n",
    "    def set_round(self, newround):\n",
    "        self.round = newround\n",
    "        if(self.round<2023 or self.round >2024):\n",
    "            return\n",
    "        if(self.round<len(self.currentyear)):\n",
    "            self.currentrace = pd.read_csv(self.dir+f'{self.year}/{self.currentyear[self.round-1]}')\n",
    "        else:\n",
    "            self.currentrace = pd.read_csv(self.dir+f'{self.year}/{self.currentyear[-1]}')\n",
    "\n",
    "    def nextround(self):\n",
    "        self.round +=1 \n",
    "        if(self.round < len(self.currentyear)):\n",
    "            self.set_round(self.round)\n",
    "        else:\n",
    "            self.round = 2\n",
    "            self.set_year(self.year+1)\n",
    "            self.set_round(self.round)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.currentrace)-1\n",
    "\n",
    "    # method for processing race data for a given index, transforming into tensors\n",
    "    # - Handles NaN values by replacing them with 0 and scales features like driver IDs and lap times\n",
    "    # - prepares sequences of lap times up to current lap for model input\n",
    "    # - extracts and scales relevant features from dataset to create input-output pairs for model training\n",
    "    \n",
    "    def __getitem__(self, i):            \n",
    "        for j in range(i+1):\n",
    "            cur = torch.tensor(self.currentrace.iloc[j].values,dtype=torch.float64)\n",
    "            cur[cur != cur] = 0\n",
    "            for k in range(0,100,5):\n",
    "                cur[k] =cur[k]/100\n",
    "                cur[k+4] = cur[k+4]/10\n",
    "            if j==0:\n",
    "                cur_ret = cur.clone()\n",
    "            elif j==1:\n",
    "                cur_ret = cur_ret.unsqueeze(0)\n",
    "                cur_ret = torch.cat((cur_ret,cur.clone().unsqueeze(0)), dim = 0)\n",
    "            else:\n",
    "                cur_ret = torch.cat((cur_ret,cur.clone().unsqueeze(0)),dim = 0)\n",
    "                \n",
    "            next = torch.tensor(self.currentrace.iloc[i+1].values,dtype=torch.float64)\n",
    "            next_exp = torch.cat((next[0:1],next[2:4],next[5:6]),0)\n",
    "            for k in range(1,20):\n",
    "                next_exp = torch.cat((\n",
    "                    next_exp,\n",
    "                    next[2+5*k:4+5*k],\n",
    "                    next[5+5*k:6+5*k]\n",
    "                ),0)\n",
    "            next_exp[next_exp!=next_exp] = 0\n",
    "            for k in range(0,60,3):\n",
    "                next_exp[k+2] = next_exp[k+2]/10\n",
    "            if j == 0:\n",
    "                next_ret = next_exp.clone()\n",
    "            elif j == 1:\n",
    "                next_ret = next_ret.unsqueeze(0)\n",
    "                next_ret = torch.cat((next_ret,next_exp.clone().unsqueeze(0)),dim=0)\n",
    "            else:\n",
    "                next_ret = torch.cat((next_ret,next_exp.clone().unsqueeze(0)),dim=0)\n",
    "        return (cur_ret, next_ret)"
   ],
   "id": "c26c184b205be885",
   "outputs": [],
   "execution_count": 657
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:34.566514Z",
     "start_time": "2024-08-20T20:51:34.537594Z"
    }
   },
   "cell_type": "code",
   "source": "ds = RaceDataSet(\"/Users/theebankumaresan/Documents/Programming/Python/f1lapbylap/f1LapbyLap/LapData/\")",
   "id": "d590efec893f1c5",
   "outputs": [],
   "execution_count": 658
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:38.683567Z",
     "start_time": "2024-08-20T20:51:38.676765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds.nextround()\n",
    "ds.year"
   ],
   "id": "7f85050352452316",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 659
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:39.711310Z",
     "start_time": "2024-08-20T20:51:39.696752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cur,n = ds[1]\n",
    "cur"
   ],
   "id": "da55c78664664598",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 9.5467e-01,\n",
       "         7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 9.5858e-01, 6.3000e+01,\n",
       "         5.0000e+00, 0.0000e+00, 1.0000e-01, 9.5079e-01, 5.5000e+01, 4.0000e+00,\n",
       "         0.0000e+00, 1.0000e-01, 9.4945e-01, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
       "         1.0000e-01, 9.4862e-01, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
       "         9.5154e-01, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 9.6235e-01,\n",
       "         2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 9.5698e-01, 2.3000e+01,\n",
       "         1.5000e+01, 0.0000e+00, 1.0000e-01, 9.6315e-01, 2.2000e+01, 1.1000e+01,\n",
       "         0.0000e+00, 1.0000e-01, 9.5697e-01, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
       "         1.0000e-01, 9.5880e-01, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
       "         9.6589e-01, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 9.4723e-01,\n",
       "         1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 9.6268e-01, 1.1000e+01,\n",
       "         9.0000e+00, 0.0000e+00, 1.0000e-01, 9.5173e-01, 1.0000e+01, 7.0000e+00,\n",
       "         0.0000e+00, 1.0000e-01, 9.5089e-01, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "         1.0000e-01, 9.4853e-01, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
       "         9.5974e-01, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 9.6827e-01,\n",
       "         1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 9.4718e+01],\n",
       "        [9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 3.2801e+00,\n",
       "         7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 3.3271e+00, 6.3000e+01,\n",
       "         5.0000e+00, 0.0000e+00, 1.0000e-01, 4.3434e+00, 5.5000e+01, 4.0000e+00,\n",
       "         0.0000e+00, 1.0000e-01, 3.2620e+00, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
       "         1.0000e-01, 3.2651e+00, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
       "         3.2915e+00, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 3.3506e+00,\n",
       "         2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 3.3076e+00, 2.3000e+01,\n",
       "         1.5000e+01, 0.0000e+00, 1.0000e-01, 3.3221e+00, 2.2000e+01, 1.1000e+01,\n",
       "         0.0000e+00, 1.0000e-01, 3.3109e+00, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
       "         1.0000e-01, 3.3359e+00, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
       "         3.3679e+00, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 3.2529e+00,\n",
       "         1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 3.3418e+00, 1.1000e+01,\n",
       "         9.0000e+00, 0.0000e+00, 1.0000e-01, 3.2987e+00, 1.0000e+01, 7.0000e+00,\n",
       "         0.0000e+00, 1.0000e-01, 3.3024e+00, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "         1.0000e-01, 3.2356e+00, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
       "         3.3185e+00, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 3.3379e+00,\n",
       "         1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 3.2734e+02]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 660
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:41.931259Z",
     "start_time": "2024-08-20T20:51:41.925504Z"
    }
   },
   "cell_type": "code",
   "source": "cur_pack = nn.utils.rnn.pack_padded_sequence(cur.unsqueeze(0),[50],batch_first=True)",
   "id": "be384aa43544bf6b",
   "outputs": [],
   "execution_count": 661
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:51:43.413157Z",
     "start_time": "2024-08-20T20:51:43.402056Z"
    }
   },
   "cell_type": "code",
   "source": "print(cur_pack)",
   "id": "79e854cd80731643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 9.5467e-01,\n",
      "         7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 9.5858e-01, 6.3000e+01,\n",
      "         5.0000e+00, 0.0000e+00, 1.0000e-01, 9.5079e-01, 5.5000e+01, 4.0000e+00,\n",
      "         0.0000e+00, 1.0000e-01, 9.4945e-01, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
      "         1.0000e-01, 9.4862e-01, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
      "         9.5154e-01, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 9.6235e-01,\n",
      "         2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 9.5698e-01, 2.3000e+01,\n",
      "         1.5000e+01, 0.0000e+00, 1.0000e-01, 9.6315e-01, 2.2000e+01, 1.1000e+01,\n",
      "         0.0000e+00, 1.0000e-01, 9.5697e-01, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
      "         1.0000e-01, 9.5880e-01, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
      "         9.6589e-01, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 9.4723e-01,\n",
      "         1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 9.6268e-01, 1.1000e+01,\n",
      "         9.0000e+00, 0.0000e+00, 1.0000e-01, 9.5173e-01, 1.0000e+01, 7.0000e+00,\n",
      "         0.0000e+00, 1.0000e-01, 9.5089e-01, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e-01, 9.4853e-01, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
      "         9.5974e-01, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 9.6827e-01,\n",
      "         1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 9.4718e+01],\n",
      "        [9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 3.2801e+00,\n",
      "         7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 3.3271e+00, 6.3000e+01,\n",
      "         5.0000e+00, 0.0000e+00, 1.0000e-01, 4.3434e+00, 5.5000e+01, 4.0000e+00,\n",
      "         0.0000e+00, 1.0000e-01, 3.2620e+00, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
      "         1.0000e-01, 3.2651e+00, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
      "         3.2915e+00, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 3.3506e+00,\n",
      "         2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 3.3076e+00, 2.3000e+01,\n",
      "         1.5000e+01, 0.0000e+00, 1.0000e-01, 3.3221e+00, 2.2000e+01, 1.1000e+01,\n",
      "         0.0000e+00, 1.0000e-01, 3.3109e+00, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
      "         1.0000e-01, 3.3359e+00, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
      "         3.3679e+00, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 3.2529e+00,\n",
      "         1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 3.3418e+00, 1.1000e+01,\n",
      "         9.0000e+00, 0.0000e+00, 1.0000e-01, 3.2987e+00, 1.0000e+01, 7.0000e+00,\n",
      "         0.0000e+00, 1.0000e-01, 3.3024e+00, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "         1.0000e-01, 3.2356e+00, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
      "         3.3185e+00, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 3.3379e+00,\n",
      "         1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 3.2734e+02]],\n",
      "       dtype=torch.float64), batch_sizes=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "execution_count": 662
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Helper functions for displaying input/output tensors in english\n",
    "- converts tensor into a chart which shows: driver name, position, inpit, laptime and status"
   ],
   "id": "8c1a3522b3308552"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:57:01.459651Z",
     "start_time": "2024-08-20T20:57:01.446182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def displaypositions(input,output):\n",
    "    print(input)\n",
    "    print(output)\n",
    "    _lapdata = input.detach().clone()\n",
    "    _outdata = output.detach().clone()\n",
    "    # _outdata = _outdata.apply_(lambda x: x*100)\n",
    "    _name, _country, _location = circuit_info(int(_lapdata[0].item()*100))\n",
    "    j = 0\n",
    "    for i in range(1,100,5):\n",
    "        _num, _code, _fn, _ln, _ = driver_info(int(_lapdata[i].item()))\n",
    "        _pos = _outdata[j].item()\n",
    "        _time = _outdata[j+3].item()\n",
    "        _status = _outdata[j+2].item()\n",
    "        # _statusstr = status_info(round(_status))\n",
    "        j += 3\n",
    "        print(f'Driver: {_num}  {_fn} {_ln}')\n",
    "        print(f'Position: {_pos}')\n",
    "        print(f'Laptime: {_time}')\n",
    "        # print(f'Status: {_statusstr}')"
   ],
   "id": "7d253bc2895ae06d",
   "outputs": [],
   "execution_count": 689
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T20:58:54.935875Z",
     "start_time": "2024-08-20T20:58:54.915207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds[1]\n",
    "# displaypositions(ds[1][0][0], ds[1][0][1])"
   ],
   "id": "4267901b6a3d1df1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 9.5467e-01,\n",
       "          7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 9.5858e-01, 6.3000e+01,\n",
       "          5.0000e+00, 0.0000e+00, 1.0000e-01, 9.5079e-01, 5.5000e+01, 4.0000e+00,\n",
       "          0.0000e+00, 1.0000e-01, 9.4945e-01, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
       "          1.0000e-01, 9.4862e-01, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
       "          9.5154e-01, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 9.6235e-01,\n",
       "          2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 9.5698e-01, 2.3000e+01,\n",
       "          1.5000e+01, 0.0000e+00, 1.0000e-01, 9.6315e-01, 2.2000e+01, 1.1000e+01,\n",
       "          0.0000e+00, 1.0000e-01, 9.5697e-01, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
       "          1.0000e-01, 9.5880e-01, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
       "          9.6589e-01, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 9.4723e-01,\n",
       "          1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 9.6268e-01, 1.1000e+01,\n",
       "          9.0000e+00, 0.0000e+00, 1.0000e-01, 9.5173e-01, 1.0000e+01, 7.0000e+00,\n",
       "          0.0000e+00, 1.0000e-01, 9.5089e-01, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "          1.0000e-01, 9.4853e-01, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
       "          9.5974e-01, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 9.6827e-01,\n",
       "          1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 9.4718e+01],\n",
       "         [9.0000e-02, 8.1000e+01, 1.0000e+01, 0.0000e+00, 1.0000e-01, 3.2801e+00,\n",
       "          7.7000e+01, 1.3000e+01, 0.0000e+00, 1.0000e-01, 3.3271e+00, 6.3000e+01,\n",
       "          5.0000e+00, 0.0000e+00, 1.0000e-01, 4.3434e+00, 5.5000e+01, 4.0000e+00,\n",
       "          0.0000e+00, 1.0000e-01, 3.2620e+00, 4.4000e+01, 3.0000e+00, 0.0000e+00,\n",
       "          1.0000e-01, 3.2651e+00, 3.1000e+01, 8.0000e+00, 0.0000e+00, 1.0000e-01,\n",
       "          3.2915e+00, 2.7000e+01, 1.8000e+01, 0.0000e+00, 1.0000e-01, 3.3506e+00,\n",
       "          2.4000e+01, 1.2000e+01, 0.0000e+00, 1.0000e-01, 3.3076e+00, 2.3000e+01,\n",
       "          1.5000e+01, 0.0000e+00, 1.0000e-01, 3.3221e+00, 2.2000e+01, 1.1000e+01,\n",
       "          0.0000e+00, 1.0000e-01, 3.3109e+00, 2.0000e+01, 1.7000e+01, 0.0000e+00,\n",
       "          1.0000e-01, 3.3359e+00, 1.8000e+01, 2.0000e+01, 0.0000e+00, 1.0000e-01,\n",
       "          3.3679e+00, 1.6000e+01, 1.0000e+00, 0.0000e+00, 1.0000e-01, 3.2529e+00,\n",
       "          1.4000e+01, 1.9000e+01, 0.0000e+00, 1.0000e-01, 3.3418e+00, 1.1000e+01,\n",
       "          9.0000e+00, 0.0000e+00, 1.0000e-01, 3.2987e+00, 1.0000e+01, 7.0000e+00,\n",
       "          0.0000e+00, 1.0000e-01, 3.3024e+00, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "          1.0000e-01, 3.2356e+00, 3.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e-01,\n",
       "          3.3185e+00, 2.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e-01, 3.3379e+00,\n",
       "          1.0000e+00, 6.0000e+00, 0.0000e+00, 1.0000e-01, 3.2734e+02]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[  9.0000,   6.0000,   0.0000, 103.7990,  15.0000,   0.0000, 105.4940,\n",
       "            7.0000,   0.0000, 103.4730,   3.0000,   0.0000, 102.6590,   4.0000,\n",
       "            0.0000, 102.9160,   7.0000,   0.0000, 104.7890,  19.0000,   0.0000,\n",
       "          105.2690,  12.0000,   0.0000, 105.6580,  14.0000,   0.0000, 105.5760,\n",
       "           11.0000,   0.0000, 104.8200,  16.0000,   0.0000, 105.3950,  20.0000,\n",
       "            0.0000, 104.5670,   2.0000,   0.0000, 102.6190,  18.0000,   0.0000,\n",
       "          105.4240,   9.0000,   0.0000, 104.8840,  10.0000,   0.0000, 104.9600,\n",
       "            1.0000,   0.0000, 101.9820,  13.0000,   0.0000, 105.2280,  17.0000,\n",
       "            0.0000, 105.3910,   5.0000,   0.0000, 103.0090],\n",
       "         [  9.0000,   6.0000,   0.0000, 103.7990,  15.0000,   0.0000, 105.4940,\n",
       "            7.0000,   0.0000, 103.4730,   3.0000,   0.0000, 102.6590,   4.0000,\n",
       "            0.0000, 102.9160,   7.0000,   0.0000, 104.7890,  19.0000,   0.0000,\n",
       "          105.2690,  12.0000,   0.0000, 105.6580,  14.0000,   0.0000, 105.5760,\n",
       "           11.0000,   0.0000, 104.8200,  16.0000,   0.0000, 105.3950,  20.0000,\n",
       "            0.0000, 104.5670,   2.0000,   0.0000, 102.6190,  18.0000,   0.0000,\n",
       "          105.4240,   9.0000,   0.0000, 104.8840,  10.0000,   0.0000, 104.9600,\n",
       "            1.0000,   0.0000, 101.9820,  13.0000,   0.0000, 105.2280,  17.0000,\n",
       "            0.0000, 105.3910,   5.0000,   0.0000, 103.0090]],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 694
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating the LSTM Model",
   "id": "45abb0d42f0d6f44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T15:24:16.421786Z",
     "start_time": "2024-08-16T15:24:16.416330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RacePredictor(nn.Module):\n",
    "    def __init__(self, input_size, output_size, lstm_hids, lstm_layers, dropout):\n",
    "        super(RacePredictor, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.lstm_hids = lstm_hids\n",
    "        self.lstm_layers = lstm_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=lstm_hids, num_layers=lstm_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=lstm_hids, out_features=output_size)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc.weight.data)\n",
    "        \n",
    "        for name,params in self.named_parameters():\n",
    "            if name[:6] == 'weight':\n",
    "                nn.init.xavier_uniform_(params)\n",
    "            elif name[:4] == 'bias':\n",
    "                nn.init.constant_(params, 0.0)\n",
    "                \n",
    "    def forward(self, ins, prev_states = None):\n",
    "        lstm_outs, next_states = self.lstm(ins, prev_states)\n",
    "        outs = self.fc(lstm_outs)\n",
    "        return outs, next_states\n",
    "    \n",
    "    def zero_states(self):\n",
    "        hidden_state = torch.zeros(self.lstm_layers,1,self.lstm_hids)\n",
    "        cell_state = torch.zeros(self.lstm_layers,1,self.lstm_hids)\n",
    "        return(hidden_state, cell_state)"
   ],
   "id": "71c3007e4ecb897e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Helper functions for training the LSTM model\n",
    "- training method, testing method and method to do both"
   ],
   "id": "8d5ce80d873f7cbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "648973adcef7c9e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
